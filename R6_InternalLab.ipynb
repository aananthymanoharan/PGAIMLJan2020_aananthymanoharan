{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeoiMbH7djEv"
   },
   "source": [
    "# Stock prices dataset\n",
    "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
    "\n",
    "## Description\n",
    "A brief description of columns.\n",
    "- open: The opening market price of the equity symbol on the date\n",
    "- high: The highest market price of the equity symbol on the date\n",
    "- low: The lowest recorded market price of the equity symbol on the date\n",
    "- close: The closing recorded price of the equity symbol on the date\n",
    "- symbol: Symbol of the listed company\n",
    "- volume: Total traded volume of the equity symbol on the date\n",
    "- date: Date of record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSoYY2nII_UW"
   },
   "source": [
    "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PGqq9f8VdLba"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_88voqAH-O6J"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRHCeJqP-evf"
   },
   "source": [
    "### Load the data\n",
    "- load the csv file and read it using pandas\n",
    "- file name is prices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gr4YcffYd1FQ",
    "outputId": "c1036325-662c-4d91-bc27-24da1149da58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# run this cell to to mount the google drive if you are using google colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sF8rmknxhfMI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/content/drive/My Drive/Database/prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j88c9NGwkMrb",
    "outputId": "7a6b9eb8-73e6-43d2-bf18-e8900466de44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 851264 entries, 0 to 851263\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   date    851264 non-null  object \n",
      " 1   symbol  851264 non-null  object \n",
      " 2   open    851264 non-null  float64\n",
      " 3   close   851264 non-null  float64\n",
      " 4   low     851264 non-null  float64\n",
      " 5   high    851264 non-null  float64\n",
      " 6   volume  851264 non-null  float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "R3yS8IfpoO67",
    "outputId": "1e0dafc4-f42c-4e7a-ed58-a86c7d68c738"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open  ...         low        high     volume\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-tiWlXOoR0J",
    "outputId": "aeec9399-2a4f-47ec-f4bb-b556cd03bbd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851264, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlLKVPVH_BCT"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxoGynuBeO4t"
   },
   "source": [
    "### Drop null\n",
    "- Drop null values if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_yuwJJIeeUaD"
   },
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "#df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eG7e7TTojOz",
    "outputId": "4dc2f450-4f4d-44d0-d677-ca4664d5be5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851264, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J4BlzVA_gZd"
   },
   "source": [
    "### Drop columns\n",
    "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
    "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IKEK8aEE_Csx"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['date','symbol','volume'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTPhO6v-AiZt"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsZXmF3NAkna"
   },
   "source": [
    "### Print the dataframe\n",
    "- print the modified dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "aKs04iIHAjxN",
    "outputId": "262ad03f-c895-4979-eab4-009616ccc193"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266342</th>\n",
       "      <td>45.849998</td>\n",
       "      <td>45.599998</td>\n",
       "      <td>45.189999</td>\n",
       "      <td>45.849998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152796</th>\n",
       "      <td>49.439999</td>\n",
       "      <td>49.439999</td>\n",
       "      <td>48.830002</td>\n",
       "      <td>49.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591667</th>\n",
       "      <td>73.430001</td>\n",
       "      <td>74.219995</td>\n",
       "      <td>73.229997</td>\n",
       "      <td>74.419999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46551</th>\n",
       "      <td>30.040001</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>29.120001</td>\n",
       "      <td>31.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570479</th>\n",
       "      <td>119.459999</td>\n",
       "      <td>121.389999</td>\n",
       "      <td>119.459999</td>\n",
       "      <td>121.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850406</th>\n",
       "      <td>64.510002</td>\n",
       "      <td>64.360001</td>\n",
       "      <td>64.269997</td>\n",
       "      <td>64.739998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256561</th>\n",
       "      <td>86.660004</td>\n",
       "      <td>86.330002</td>\n",
       "      <td>85.849998</td>\n",
       "      <td>86.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446935</th>\n",
       "      <td>15.550000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>15.310000</td>\n",
       "      <td>15.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458305</th>\n",
       "      <td>41.369999</td>\n",
       "      <td>41.439999</td>\n",
       "      <td>41.119999</td>\n",
       "      <td>41.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135875</th>\n",
       "      <td>15.550000</td>\n",
       "      <td>15.680000</td>\n",
       "      <td>15.470000</td>\n",
       "      <td>15.690000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              open       close         low        high\n",
       "266342   45.849998   45.599998   45.189999   45.849998\n",
       "152796   49.439999   49.439999   48.830002   49.669998\n",
       "591667   73.430001   74.219995   73.229997   74.419999\n",
       "46551    30.040001   31.080000   29.120001   31.180000\n",
       "570479  119.459999  121.389999  119.459999  121.529999\n",
       "850406   64.510002   64.360001   64.269997   64.739998\n",
       "256561   86.660004   86.330002   85.849998   86.750000\n",
       "446935   15.550000   15.380000   15.310000   15.690000\n",
       "458305   41.369999   41.439999   41.119999   41.549999\n",
       "135875   15.550000   15.680000   15.470000   15.690000"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8u_jlbABTip"
   },
   "source": [
    "### Get features and label from the dataset in separate variable\n",
    "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
    "- Take \"open\" \"low\", \"high\" columns as features\n",
    "- Take \"close\" column as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xQjCMzUXBJbg"
   },
   "outputs": [],
   "source": [
    "X=df.drop('close',axis=1)\n",
    "y=df['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ejX9oexbrNqs"
   },
   "outputs": [],
   "source": [
    "#y=df.pop('close')\n",
    "#X=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yd4lR0jbreqy",
    "outputId": "3326c645-4a01-43cc-d647-33f69ee0081a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         125.839996\n",
       "1         119.980003\n",
       "2         114.949997\n",
       "3         116.620003\n",
       "4         114.970001\n",
       "             ...    \n",
       "851259    103.199997\n",
       "851260     43.040001\n",
       "851261     53.529999\n",
       "851262     45.450001\n",
       "851263     53.630001\n",
       "Name: close, Length: 851264, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "7ciShp48rhJv",
    "outputId": "b17bfb96-bce7-443b-9b52-7199d721a8ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.430000</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.480003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851259</th>\n",
       "      <td>103.309998</td>\n",
       "      <td>102.849998</td>\n",
       "      <td>103.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851260</th>\n",
       "      <td>43.070000</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>43.310001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851261</th>\n",
       "      <td>53.639999</td>\n",
       "      <td>53.270000</td>\n",
       "      <td>53.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851262</th>\n",
       "      <td>44.730000</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851263</th>\n",
       "      <td>54.200001</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>54.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851264 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open         low        high\n",
       "0       123.430000  122.309998  126.250000\n",
       "1       125.239998  119.940002  125.540001\n",
       "2       116.379997  114.930000  119.739998\n",
       "3       115.480003  113.500000  117.440002\n",
       "4       117.010002  114.089996  117.330002\n",
       "...            ...         ...         ...\n",
       "851259  103.309998  102.849998  103.930000\n",
       "851260   43.070000   42.689999   43.310001\n",
       "851261   53.639999   53.270000   53.740002\n",
       "851262   44.730000   44.410000   45.590000\n",
       "851263   54.200001   53.389999   54.480000\n",
       "\n",
       "[851264 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vGtnapgBIJm"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pZAKdJ5gcrm"
   },
   "source": [
    "### Create train and test sets\n",
    "- Split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KalRqA6Rgqsn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTAKzlxZBz0z"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7BU2qxEg0Ki"
   },
   "source": [
    "### Scaling\n",
    "- Scale the data (features only)\n",
    "- Use StandarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AcO8SlhPhBkR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vp6Paan2xi7X",
    "outputId": "597b2349-0f17-463e-c35a-bcb04677e6bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thkywvwwxmsv",
    "outputId": "334c532e-10c1-496f-b8e8-ab00c3df3a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hviXIjNXyPtn",
    "outputId": "028d9ae4-02bb-403f-f570-e50280064480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xY3FqY4lyVs4",
    "outputId": "79752bb5-244a-44f5-c1a0-0ac3da53b277"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TWpN0nVTpUx"
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sj0LYNkhR-L"
   },
   "source": [
    "### Convert data to NumPy array\n",
    "- Convert features and labels to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VfQsC_pmyY-M"
   },
   "outputs": [],
   "source": [
    "#since the features are already in numpy array format lets convert labels alone to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X6mIfuTxhbTT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKO-DAEBx-fs",
    "outputId": "2a09fab5-0495-4977-f821-18280afc80e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gITkn7qsyBUI",
    "outputId": "ad971cf2-5a30-47c1-cf4c-9fb3df5e2851"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmXUGc2oTspa"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl2M9whFh6mh"
   },
   "source": [
    "### Define Model\n",
    "- Initialize a Sequential model\n",
    "- Add a Flatten layer\n",
    "- Add a Dense layer with one neuron as output\n",
    "  - add 'linear' as activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72DImXng29_A",
    "outputId": "d565a2b1-267d-4185-bc2c-4bcc62b6f912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(638448, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clJQWzn03Lp_",
    "outputId": "cb5bae8c-0562-4c5a-94e3-1b333f299919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915344"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkiBpORmiegL",
    "outputId": "fd758514-3801-4cb9-b87f-d3d908b0bb1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Flattening means to remove all of the dimensions except one\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Input\n",
    "\n",
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1,input_shape=(3,),activation='linear'))\n",
    "model.output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aUyyKD1s7diH"
   },
   "outputs": [],
   "source": [
    "#Other way to do this \n",
    "#Flatten and then do the Dense layer\n",
    "model1 = Sequential ([Input(shape=(3,)),Flatten(),Dense(1,activation='linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtMbS6l4J1lD",
    "outputId": "e98eeeb0-eadc-4e63-98a6-10aeadcb4a33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a0wr94aTyjg"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNZPb5lKioX0"
   },
   "source": [
    "### Compile the model\n",
    "- Compile the model\n",
    "- Use \"sgd\" optimizer\n",
    "- for calculating loss, use mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZEQUP3VaiuT2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mse')\n",
    "#model.compile(optimizer='sgd',loss= tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gM3ed-DzBI0A",
    "outputId": "cd929548-b14b-4735-f1e4-1d9ccb08abf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YWm5s9n5J5zO"
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer='sgd',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRUmCeASJ8Qt",
    "outputId": "469deba3-70a2-4afc-df16-a572dbf74d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbBpnOtfT0wd"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9o45OHdjDhA"
   },
   "source": [
    "### Fit the model\n",
    "- epochs: 50\n",
    "- batch size: 128\n",
    "- specify validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Y6tA30XjOH2",
    "outputId": "00b0769b-538b-4efc-e9b2-38efb17b1199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 37.8809 - val_loss: 1.2339\n",
      "Epoch 2/50\n",
      "4988/4988 [==============================] - 5s 985us/step - loss: 0.9673 - val_loss: 1.1351\n",
      "Epoch 3/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9594 - val_loss: 1.1727\n",
      "Epoch 4/50\n",
      "4988/4988 [==============================] - 8s 2ms/step - loss: 0.9522 - val_loss: 1.1472\n",
      "Epoch 5/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9452 - val_loss: 1.2817\n",
      "Epoch 6/50\n",
      "4988/4988 [==============================] - 5s 978us/step - loss: 0.9371 - val_loss: 1.2296\n",
      "Epoch 7/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9315 - val_loss: 1.0742\n",
      "Epoch 8/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9248 - val_loss: 1.2066\n",
      "Epoch 9/50\n",
      "4988/4988 [==============================] - 5s 976us/step - loss: 0.9179 - val_loss: 1.4237\n",
      "Epoch 10/50\n",
      "4988/4988 [==============================] - 5s 979us/step - loss: 0.9115 - val_loss: 1.2319\n",
      "Epoch 11/50\n",
      "4988/4988 [==============================] - 5s 985us/step - loss: 0.9047 - val_loss: 1.0899\n",
      "Epoch 12/50\n",
      "4988/4988 [==============================] - 5s 980us/step - loss: 0.8985 - val_loss: 1.0689\n",
      "Epoch 13/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8918 - val_loss: 1.0213\n",
      "Epoch 14/50\n",
      "4988/4988 [==============================] - 5s 999us/step - loss: 0.8842 - val_loss: 1.1693\n",
      "Epoch 15/50\n",
      "4988/4988 [==============================] - 5s 1000us/step - loss: 0.8802 - val_loss: 1.1951\n",
      "Epoch 16/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.8729 - val_loss: 1.0281\n",
      "Epoch 17/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.8663 - val_loss: 1.1262\n",
      "Epoch 18/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8620 - val_loss: 1.0410\n",
      "Epoch 19/50\n",
      "4988/4988 [==============================] - 5s 995us/step - loss: 0.8542 - val_loss: 1.1265\n",
      "Epoch 20/50\n",
      "4988/4988 [==============================] - 5s 984us/step - loss: 0.8496 - val_loss: 1.4601\n",
      "Epoch 21/50\n",
      "4988/4988 [==============================] - 5s 983us/step - loss: 0.8429 - val_loss: 1.1678\n",
      "Epoch 22/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.8383 - val_loss: 1.1387\n",
      "Epoch 23/50\n",
      "4988/4988 [==============================] - 5s 985us/step - loss: 0.8325 - val_loss: 1.3291\n",
      "Epoch 24/50\n",
      "4988/4988 [==============================] - 5s 983us/step - loss: 0.8277 - val_loss: 1.1164\n",
      "Epoch 25/50\n",
      "4988/4988 [==============================] - 5s 982us/step - loss: 0.8225 - val_loss: 1.0162\n",
      "Epoch 26/50\n",
      "4988/4988 [==============================] - 5s 982us/step - loss: 0.8165 - val_loss: 1.1615\n",
      "Epoch 27/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8116 - val_loss: 1.1036\n",
      "Epoch 28/50\n",
      "4988/4988 [==============================] - 5s 998us/step - loss: 0.8049 - val_loss: 1.0981\n",
      "Epoch 29/50\n",
      "4988/4988 [==============================] - 5s 983us/step - loss: 0.8015 - val_loss: 0.9827\n",
      "Epoch 30/50\n",
      "4988/4988 [==============================] - 5s 979us/step - loss: 0.7958 - val_loss: 0.9592\n",
      "Epoch 31/50\n",
      "4988/4988 [==============================] - 5s 977us/step - loss: 0.7917 - val_loss: 1.0549\n",
      "Epoch 32/50\n",
      "4988/4988 [==============================] - 5s 986us/step - loss: 0.7865 - val_loss: 0.9490\n",
      "Epoch 33/50\n",
      "4988/4988 [==============================] - 5s 980us/step - loss: 0.7816 - val_loss: 0.9783\n",
      "Epoch 34/50\n",
      "4988/4988 [==============================] - 5s 994us/step - loss: 0.7768 - val_loss: 1.1495\n",
      "Epoch 35/50\n",
      "4988/4988 [==============================] - 5s 994us/step - loss: 0.7719 - val_loss: 1.0198\n",
      "Epoch 36/50\n",
      "4988/4988 [==============================] - 5s 985us/step - loss: 0.7664 - val_loss: 0.9657\n",
      "Epoch 37/50\n",
      "4988/4988 [==============================] - 5s 982us/step - loss: 0.7623 - val_loss: 1.1045\n",
      "Epoch 38/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.7575 - val_loss: 1.1306\n",
      "Epoch 39/50\n",
      "4988/4988 [==============================] - 5s 982us/step - loss: 0.7533 - val_loss: 1.0417\n",
      "Epoch 40/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.7489 - val_loss: 1.1059\n",
      "Epoch 41/50\n",
      "4988/4988 [==============================] - 5s 987us/step - loss: 0.7438 - val_loss: 0.9614\n",
      "Epoch 42/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7399 - val_loss: 0.9668\n",
      "Epoch 43/50\n",
      "4988/4988 [==============================] - 5s 995us/step - loss: 0.7364 - val_loss: 0.8917\n",
      "Epoch 44/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7318 - val_loss: 1.0263\n",
      "Epoch 45/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7269 - val_loss: 0.9331\n",
      "Epoch 46/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.7229 - val_loss: 0.8855\n",
      "Epoch 47/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7191 - val_loss: 0.8890\n",
      "Epoch 48/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7154 - val_loss: 1.0128\n",
      "Epoch 49/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7115 - val_loss: 0.9891\n",
      "Epoch 50/50\n",
      "4988/4988 [==============================] - 5s 997us/step - loss: 0.7065 - val_loss: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5d0e5ccc0>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  model.fit(X_train, y_train, epochs=50,batch_size=128,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9xnib4QKJmH",
    "outputId": "6b70219e-b726-4495-8148-ce34a9279699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 39.0575 - val_loss: 1.3241\n",
      "Epoch 2/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9819 - val_loss: 1.2623\n",
      "Epoch 3/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9736 - val_loss: 1.1322\n",
      "Epoch 4/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9680 - val_loss: 1.2475\n",
      "Epoch 5/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9593 - val_loss: 1.2831\n",
      "Epoch 6/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9541 - val_loss: 1.2092\n",
      "Epoch 7/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.9445 - val_loss: 1.1425\n",
      "Epoch 8/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9375 - val_loss: 1.2734\n",
      "Epoch 9/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9289 - val_loss: 1.2456\n",
      "Epoch 10/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9233 - val_loss: 1.0492\n",
      "Epoch 11/50\n",
      "4988/4988 [==============================] - 6s 1ms/step - loss: 0.9180 - val_loss: 1.1633\n",
      "Epoch 12/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9122 - val_loss: 1.1491\n",
      "Epoch 13/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.9043 - val_loss: 1.2767\n",
      "Epoch 14/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8972 - val_loss: 1.1985\n",
      "Epoch 15/50\n",
      "4988/4988 [==============================] - 5s 993us/step - loss: 0.8909 - val_loss: 1.0126\n",
      "Epoch 16/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8850 - val_loss: 1.3984\n",
      "Epoch 17/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8785 - val_loss: 0.9959\n",
      "Epoch 18/50\n",
      "4988/4988 [==============================] - 5s 998us/step - loss: 0.8714 - val_loss: 1.0217\n",
      "Epoch 19/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8652 - val_loss: 1.1787\n",
      "Epoch 20/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8619 - val_loss: 1.2333\n",
      "Epoch 21/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.8554 - val_loss: 0.9989\n",
      "Epoch 22/50\n",
      "4988/4988 [==============================] - 5s 993us/step - loss: 0.8481 - val_loss: 1.1827\n",
      "Epoch 23/50\n",
      "4988/4988 [==============================] - 5s 995us/step - loss: 0.8419 - val_loss: 1.1325\n",
      "Epoch 24/50\n",
      "4988/4988 [==============================] - 5s 994us/step - loss: 0.8380 - val_loss: 1.0857\n",
      "Epoch 25/50\n",
      "4988/4988 [==============================] - 5s 983us/step - loss: 0.8324 - val_loss: 1.0925\n",
      "Epoch 26/50\n",
      "4988/4988 [==============================] - 5s 997us/step - loss: 0.8257 - val_loss: 1.1604\n",
      "Epoch 27/50\n",
      "4988/4988 [==============================] - 5s 983us/step - loss: 0.8204 - val_loss: 1.0490\n",
      "Epoch 28/50\n",
      "4988/4988 [==============================] - 5s 990us/step - loss: 0.8163 - val_loss: 1.1325\n",
      "Epoch 29/50\n",
      "4988/4988 [==============================] - 5s 1000us/step - loss: 0.8118 - val_loss: 1.1389\n",
      "Epoch 30/50\n",
      "4988/4988 [==============================] - 5s 996us/step - loss: 0.8060 - val_loss: 1.0866\n",
      "Epoch 31/50\n",
      "4988/4988 [==============================] - 5s 995us/step - loss: 0.8008 - val_loss: 0.9687\n",
      "Epoch 32/50\n",
      "4988/4988 [==============================] - 5s 979us/step - loss: 0.7947 - val_loss: 1.0768\n",
      "Epoch 33/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7909 - val_loss: 1.0850\n",
      "Epoch 34/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7858 - val_loss: 1.0972\n",
      "Epoch 35/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7816 - val_loss: 1.0725\n",
      "Epoch 36/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7749 - val_loss: 0.9614\n",
      "Epoch 37/50\n",
      "4988/4988 [==============================] - 5s 991us/step - loss: 0.7724 - val_loss: 0.9776\n",
      "Epoch 38/50\n",
      "4988/4988 [==============================] - 5s 988us/step - loss: 0.7661 - val_loss: 1.1187\n",
      "Epoch 39/50\n",
      "4988/4988 [==============================] - 5s 987us/step - loss: 0.7626 - val_loss: 1.0593\n",
      "Epoch 40/50\n",
      "4988/4988 [==============================] - 5s 994us/step - loss: 0.7568 - val_loss: 1.0097\n",
      "Epoch 41/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7515 - val_loss: 0.9145\n",
      "Epoch 42/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7482 - val_loss: 1.0003\n",
      "Epoch 43/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7435 - val_loss: 1.0480\n",
      "Epoch 44/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7405 - val_loss: 0.8176\n",
      "Epoch 45/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7348 - val_loss: 0.9543\n",
      "Epoch 46/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7318 - val_loss: 1.0284\n",
      "Epoch 47/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7264 - val_loss: 0.9325\n",
      "Epoch 48/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7234 - val_loss: 1.0298\n",
      "Epoch 49/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7190 - val_loss: 0.9574\n",
      "Epoch 50/50\n",
      "4988/4988 [==============================] - 5s 1ms/step - loss: 0.7155 - val_loss: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5ce7dbe48>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=50,batch_size=128,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AW4SEP8kT2ls"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJDoix_7JU61"
   },
   "source": [
    "### Evaluate the model\n",
    "- Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdH8pYBIjHGL",
    "outputId": "7c6d9e95-5901-4cc8-e001-0e9991947fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6651/6651 [==============================] - 5s 682us/step - loss: 0.9193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9193063974380493"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NY9F1p0sKL1Z",
    "outputId": "fbf64d29-bc23-4c0a-c2d6-5903bb90a3d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6651/6651 [==============================] - 5s 704us/step - loss: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9651097655296326"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUpDD74Xjh01"
   },
   "source": [
    "### Manual predictions\n",
    "- Test the predictions on manual inputs\n",
    "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler`\n",
    "- Example of manual input: [123.430000,\t122.30999, 116.250000]++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvuH-c31lLiJ",
    "outputId": "b8dce531-57ca-4211-93c3-54709e676812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120.05323]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sc.transform([[123.430000, 122.30999, 116.250000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7l1Q3CNLLdRh",
    "outputId": "38e38773-06bc-451b-a454-4b27b0486cff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120.07954]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(sc.transform([[123.430000, 122.30999, 116.250000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WH1Pr4KQlCh"
   },
   "source": [
    "# Build a DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74cQBsi5QlCw"
   },
   "source": [
    "### Collect Fashion mnist data from tf.keras.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wVWy0oDTr2Kj"
   },
   "outputs": [],
   "source": [
    "(trainX,trainY),(testX,testY)=tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OgYk8DxLmW7",
    "outputId": "c491c548-1e38-4052-827b-c9bf97b648b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXaJP7UyL3h7",
    "outputId": "a5a13e98-444f-4ca5-9be0-a4ca87c2e9d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXV8-JxYMFFN",
    "outputId": "1f8bfb92-6ca0-4de2-b949-aaf73ac1060e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no7aWYZyQlC1"
   },
   "source": [
    "### Change train and test labels into one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "UX6otc4wQlC2"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY,num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1KJTjdSMUzx",
    "outputId": "9d09d5dc-c2f2-4d13-9ea7-99db07661926"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjNrRTdoQlC5"
   },
   "source": [
    "### Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDJ9DHVNQlC7"
   },
   "source": [
    "### Initialize model, reshape & normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "pCDQs_g1QlC8"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBGwTTilQlDD"
   },
   "source": [
    "### Add two fully connected layers with 200 and 100 neurons respectively with `relu` activations. Add a dropout layer with `p=0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IXbfpfOzQlDF"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(200, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I8f5otcQlDJ"
   },
   "source": [
    "### Add the output layer with a fully connected layer with 10 neurons with `softmax` activation. Use `categorical_crossentropy` loss and `adam` optimizer and train the network. And, report the final validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZkvKymSd0Sr",
    "outputId": "c13eb501-884a-492d-b3a4-db65a2176f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5110 - accuracy: 0.8187 - val_loss: 0.4027 - val_accuracy: 0.8535\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3957 - accuracy: 0.8571 - val_loss: 0.3668 - val_accuracy: 0.8641\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3562 - accuracy: 0.8680 - val_loss: 0.3708 - val_accuracy: 0.8625\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3335 - accuracy: 0.8761 - val_loss: 0.3836 - val_accuracy: 0.8646\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3125 - accuracy: 0.8839 - val_loss: 0.3539 - val_accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2997 - accuracy: 0.8881 - val_loss: 0.3367 - val_accuracy: 0.8835\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2821 - accuracy: 0.8935 - val_loss: 0.3616 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2716 - accuracy: 0.8976 - val_loss: 0.3503 - val_accuracy: 0.8840\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2646 - accuracy: 0.9004 - val_loss: 0.3635 - val_accuracy: 0.8809\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2536 - accuracy: 0.9046 - val_loss: 0.3748 - val_accuracy: 0.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5cbe58f98>"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output Layer\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#train the model\n",
    "model.fit(trainX, trainY, validation_data=(testX,testY),epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbOuqU8QhfML",
    "outputId": "4ea0ff29-aa9f-423c-9568-eb0938055e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8824\n",
      "\n",
      "Test accuracy 0.8823999762535095\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(testX,testY)\n",
    "print('\\nTest accuracy', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "SYcCNX6MV4kq"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4DfKJgSdWG7J",
    "outputId": "ac67582e-e6bf-4b09-f509-bcc6bf0c118b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.7705326e-10, 2.0821693e-12, 9.6473239e-11, 2.7864178e-10,\n",
       "       2.2871505e-09, 2.1768231e-03, 1.1835631e-09, 4.6010711e-03,\n",
       "       6.4955169e-10, 9.9322212e-01], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eadbi6xaWIDq",
    "outputId": "00baae5c-de49-4c9b-9eb0-54b9ead154dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ag_t1d0WOZh",
    "outputId": "8740ff35-b657-4641-d72e-f9fd5d9fd3bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "rT0D9WHKWRCq",
    "outputId": "bce1c25c-56e7-406a-ed61-91bb51131e66"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(testX[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLHs0tE3Whep"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Questions - Lab on NNDL-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
