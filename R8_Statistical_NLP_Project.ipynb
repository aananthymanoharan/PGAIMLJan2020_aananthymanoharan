{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHYs6Z84xV8E"
   },
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n",
    "\n",
    "Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QQxgAmWzSye"
   },
   "source": [
    "**PROJECT DESCRIPTION:** Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles, \n",
    "etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to \n",
    "create a classifier that predicts multiple features ofthe author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "**• DATASET:** Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected \n",
    "posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million \n",
    "words - or approximately 35 posts and 7250 words per person. \n",
    "\n",
    "Each blog is presented as a separate file, the name of which indicates a \n",
    "blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age butfor many, \n",
    "industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "• 8240 \"10s\" blogs (ages 13-17),\n",
    "• 8086 \"20s\" blogs(ages 23-27) and\n",
    "• 2994 \"30s\" blogs (ages 33-47)\n",
    "\n",
    "For each age group, there is an equal number of male and female bloggers.\n",
    "\n",
    "Each blog in the corpus includes atleast 200 occurrences of common English words. All formatting has been stripped with two exceptions. \n",
    "Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url \n",
    "link. \n",
    "\n",
    "Link to data set: https: //ww w.kaggle.com/rtatman/blog-authorship-corpus\n",
    "\n",
    "• **PROJECT OBJECTIVE:**The need is to build a NLP classifier which can use input text parameters to determine the label/s of of the blog.\n",
    "[ Total Score: 40 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mI8X7kDM0H2Z"
   },
   "source": [
    "1. Load the dataset (5 points)\n",
    "\n",
    "  a. Tip: As the dataset is large, use fewer rows. Check what is working well on your\n",
    "machine and decide accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3mgXADQextW"
   },
   "source": [
    "Steps to import file directly from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sflMakRz1cfN"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z297ahiCc2F6",
    "outputId": "a5458d54-7802-4f01-e5fd-38e3018c31ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "#Make a directory for Kaggle\n",
    "!mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGF_KPHEc5hU",
    "outputId": "9a1cad4f-1cd3-4c6e-b38f-0d70b74db782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8lh3nLWedjtA"
   },
   "outputs": [],
   "source": [
    "#Copy kaggle.json file. Change gdrive folder based on where you have saved your json file from Kaggle\n",
    "!cp '/content/drive/MyDrive/AIML/kaggle.json' /content/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0c-uUotewrq",
    "outputId": "000167d4-9c83-47f0-b594-c61d000bc1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw------- 1 root root 73 Apr 10 13:58 kaggle.json\n"
     ]
    }
   ],
   "source": [
    "#Check if json file is there\n",
    "!ls -l /content/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuXd3cF1e3f8",
    "outputId": "ac9e9e0d-6254-42dd-bfbd-7fbed931d0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "- path is now set to: {/content}\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v{/content}\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJ4MuYI6e6iv"
   },
   "source": [
    "Verify Kaggle connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EHYVTs8e8Zg",
    "outputId": "7bdf552a-9be5-4a4d-a370-70f7854f6276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
      "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
      "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              223KB  2021-04-10 08:12:55           2369  \n",
      "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-02-17 16:10:44           1373  \n",
      "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   1GB  2021-02-18 10:08:27           1040  \n",
      "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52            228  \n",
      "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19            491  \n",
      "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            364  \n",
      "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            120  \n",
      "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39             53  \n",
      "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            218  \n",
      "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00            333  \n",
      "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54             83  \n",
      "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            144  \n",
      "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             49  \n",
      "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40             40  \n",
      "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             34  \n",
      "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             28  \n",
      "shivamb/netflix-shows                                       Netflix Movies and TV Shows                         1MB  2021-01-18 16:20:26         132180  \n",
      "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         134455  \n",
      "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         132723  \n",
      "google/tinyquickdraw                                        QuickDraw Sketches                                 11GB  2018-04-18 19:38:04           2967  \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX8dJiW1gxgi",
    "outputId": "30cfdd48-3b6d-4305-8ed0-c93a4cc59369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blog-authorship-corpus.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d rtatman/blog-authorship-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lgLgoxsg5iq",
    "outputId": "e151b62a-acce-4137-ade0-173948ba0b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace blogtext.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip -q '/content/{/content}/datasets/rtatman/blog-authorship-corpus/blog-authorship-corpus.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YXjAAvk6impz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "la2d10kKiJOV"
   },
   "outputs": [],
   "source": [
    "blog_data = pd.read_csv('/content/blogtext.csv',nrows=10000,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WUD0VMnip_S",
    "outputId": "73daef71-07b7-42dd-f8ef-356fd393149d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10000 non-null  int64 \n",
      " 1   gender  10000 non-null  object\n",
      " 2   age     10000 non-null  int64 \n",
      " 3   topic   10000 non-null  object\n",
      " 4   sign    10000 non-null  object\n",
      " 5   date    10000 non-null  object\n",
      " 6   text    10000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXYk45Zn0Ho6"
   },
   "source": [
    "2. Preprocess rows of the “text” column (7.5 points)\n",
    "\n",
    "  a. Remove unwanted characters\n",
    "\n",
    "  b. Convert text to lowercase\n",
    "\n",
    "  c. Remove unwanted spaces\n",
    "\n",
    "  d. Remove stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHsUukpoixl9"
   },
   "source": [
    "Remove id and date columns as those would not be useful to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ggJk0BIYi5hw"
   },
   "outputs": [],
   "source": [
    "blog_data.drop(labels=['id','date'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVlPIPpVjGvb"
   },
   "source": [
    "Randomise the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PcuWBsr3jRQS"
   },
   "outputs": [],
   "source": [
    "blog_data=blog_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rnr1Zbm1kgH"
   },
   "source": [
    "Data cleansing by removing unwanted characters, spaces, stop words etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-bLAV73lUly",
    "outputId": "af5ae8fa-8e8b-4e9d-be1a-1027ae04b939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   gender  10000 non-null  object\n",
      " 1   age     10000 non-null  int64 \n",
      " 2   topic   10000 non-null  object\n",
      " 3   sign    10000 non-null  object\n",
      " 4   text    10000 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jOHS2X8hlWxp"
   },
   "outputs": [],
   "source": [
    "blog_data['age']=blog_data['age'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "wwdP6ev41lkY",
    "outputId": "3f46e996-0458-482c-8c00-0d69958f579e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>good ole texas http://www.nytimes.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>Popular uprising in Basra!  Coaliti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>I cannot believe the Supreme Court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>24</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Aries</td>\n",
       "      <td>'Live In Tokyo / 5 Years In A LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Please note the following when...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender age  ...      sign                                               text\n",
       "0    male  35  ...     Aries             good ole texas http://www.nytimes.c...\n",
       "1    male  35  ...     Aries             Popular uprising in Basra!  Coaliti...\n",
       "2    male  35  ...     Aries             I cannot believe the Supreme Court ...\n",
       "3  female  24  ...     Aries                'Live In Tokyo / 5 Years In A LI...\n",
       "4    male  23  ...  Aquarius                  Please note the following when...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm24i6Ccly5q"
   },
   "source": [
    "Remove junks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "r2MVc1etmWKt"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RexiDJfpl0vn"
   },
   "outputs": [],
   "source": [
    "blog_data['cleansed_text']=blog_data['text'].apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFaVzGAN1hOf"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "Convert text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "AzM2aB9n1f8h"
   },
   "outputs": [],
   "source": [
    "blog_data['cleansed_text']=blog_data['cleansed_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wdl0gqK10QPv"
   },
   "source": [
    "Remove unwanted spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AhqeodMlmk_s"
   },
   "outputs": [],
   "source": [
    "blog_data['cleansed_text']=blog_data['cleansed_text'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4sBgDF_nhbS"
   },
   "source": [
    "check a random record to see if the cleansing is applied properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGnuPDPPm6LO",
    "outputId": "dec6b62c-966a-46bf-e55f-e80d92d9b115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleansing :            Popular uprising in Basra!  Coalition forces report jocks, cheerleaders, and rich kids taking the situation into their own hands.  Members of the marching band, chorus, and various arts clubs remain at home.         \n"
     ]
    }
   ],
   "source": [
    "print(\"Data before cleansing : {}\".format(blog_data['text'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKesUQq1myBs",
    "outputId": "88d3759a-3368-4e00-9db0-fd07ccf35020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleansing : popular uprising in basra coalition forces report jocks cheerleaders and rich kids taking the situation into their own hands members of the marching band chorus and various arts clubs remain at home\n"
     ]
    }
   ],
   "source": [
    "print(\"Data after cleansing : {}\".format(blog_data['cleansed_text'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jO5ycI-Knuj0"
   },
   "source": [
    "Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSYLHbgBnzKh",
    "outputId": "31bcb40a-f2b6-4dd6-dfcc-95c3268ae0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "rthLGzjPonha"
   },
   "outputs": [],
   "source": [
    "blog_data['cleansed_text'] = blog_data['cleansed_text'].apply(lambda words: ' '.join(word for word in words.split() if word not in stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Et1hyZTTo3Ew",
    "outputId": "e2812cbf-78fb-4a9c-81c8-dcfe98c570b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing stop words : popular uprising basra coalition forces report jocks cheerleaders rich kids taking situation hands members marching band chorus various arts clubs remain home\n"
     ]
    }
   ],
   "source": [
    "print(\"After removing stop words : {}\".format(blog_data['cleansed_text'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izxeei-cNtD5"
   },
   "source": [
    "3. As we want to make this into a multi-label classification problem, you are required to merge\n",
    "all the label columns together, so that we have all the labels together for a particular sentence\n",
    "(7.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h21TnUUs1qzV"
   },
   "source": [
    "a. Label columns to merge: “gender”, “age”, “topic”, “sign”\n",
    "\n",
    "b. After completing the previous step, there should be only two columns in your data\n",
    "frame i.e. “text” and “labels” as shown in the below image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "F0ycsNDl16Om"
   },
   "outputs": [],
   "source": [
    "blog_data['labels']=blog_data.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yOTbImKWpXZ_"
   },
   "outputs": [],
   "source": [
    "blog_data=blog_data[['cleansed_text','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dn1ch9oOpd9D",
    "outputId": "6c92f8d6-75b4-4887-803d-239f8ce391d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   cleansed_text  10000 non-null  object\n",
      " 1   labels         10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "blog_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "XVdnxYbSpjer",
    "outputId": "efc9efbb-0ee6-4a4f-c6d6-da91d6c9e588"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleansed_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good ole texas http www nytimes com opinion he...</td>\n",
       "      <td>[male, 35, Technology, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>popular uprising basra coalition forces report...</td>\n",
       "      <td>[male, 35, Technology, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cannot believe supreme court used technicality...</td>\n",
       "      <td>[male, 35, Technology, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>live tokyo years livetime dvd release updated ...</td>\n",
       "      <td>[female, 24, indUnk, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>please note following using mobile receive pho...</td>\n",
       "      <td>[male, 23, Internet, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urllink resume form</td>\n",
       "      <td>[male, 24, BusinessServices, Cancer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>today veri fun lessons played round chess fren...</td>\n",
       "      <td>[male, 14, Student, Libra]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weeps laughs maniacally thrashes leather strap...</td>\n",
       "      <td>[male, 35, Technology, Aries]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hi anne sophie invited group however would lov...</td>\n",
       "      <td>[female, 25, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>watch napolean</td>\n",
       "      <td>[male, 35, Technology, Aries]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       cleansed_text                                labels\n",
       "0  good ole texas http www nytimes com opinion he...         [male, 35, Technology, Aries]\n",
       "1  popular uprising basra coalition forces report...         [male, 35, Technology, Aries]\n",
       "2  cannot believe supreme court used technicality...         [male, 35, Technology, Aries]\n",
       "3  live tokyo years livetime dvd release updated ...           [female, 24, indUnk, Aries]\n",
       "4  please note following using mobile receive pho...        [male, 23, Internet, Aquarius]\n",
       "5                                urllink resume form  [male, 24, BusinessServices, Cancer]\n",
       "6  today veri fun lessons played round chess fren...            [male, 14, Student, Libra]\n",
       "7  weeps laughs maniacally thrashes leather strap...         [male, 35, Technology, Aries]\n",
       "8  hi anne sophie invited group however would lov...            [female, 25, Student, Leo]\n",
       "9                                     watch napolean         [male, 35, Technology, Aries]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HkdlYGbMsZT8"
   },
   "outputs": [],
   "source": [
    "X=blog_data['cleansed_text']\n",
    "y=blog_data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meq_OVF41tpl"
   },
   "source": [
    "Separate features and labels, and split the data into training and testing (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DHeD0d2917VD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c4SZ-x-WQtN",
    "outputId": "2074e00e-6fe3-4bab-da94-c232ee06531b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7jHS1Uo1zRr"
   },
   "source": [
    "Vectorize the features (5 points)\n",
    "\n",
    "a. Create a Bag of Words using count vectorizer\n",
    "\n",
    "  i. Use ngram_range=(1, 2)\n",
    "\n",
    "  ii. Vectorize training and testing features\n",
    "\n",
    "b. Print the term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dj3tvTYi19aG"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WbefzQCr18-H"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(binary=True, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "5kPal12tspKA"
   },
   "outputs": [],
   "source": [
    "X_train=vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDKts7bmtOCi",
    "outputId": "b78d6382-8e7f-4852-9a9b-d9110baa75bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x468778 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 495 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "GAj3_nkBoy9v"
   },
   "outputs": [],
   "source": [
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48YlR5nGo0s4",
    "outputId": "0d8be19a-3dc1-47c1-a8bf-1041da879174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x468778 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIWQocr1tQ7d",
    "outputId": "b2decc8e-d123-4b7d-d3b2-0fb594b9f69c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa amazing',\n",
       " 'aa keeps',\n",
       " 'aa nice',\n",
       " 'aaa',\n",
       " 'aaa come',\n",
       " 'aaa joe',\n",
       " 'aaa looks',\n",
       " 'aaa someone',\n",
       " 'aaa take',\n",
       " 'aaa tow',\n",
       " 'aaa travel',\n",
       " 'aaaa',\n",
       " 'aaaa jet',\n",
       " 'aaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaahhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaahhhhhhhhhhhhhhhhhhh hw',\n",
       " 'aaaaaaaaah',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaaah fade',\n",
       " 'aaaaack',\n",
       " 'aaaaahhhh',\n",
       " 'aaaaahhhh heath',\n",
       " 'aaaah',\n",
       " 'aaaah wisdom',\n",
       " 'aaah',\n",
       " 'aaah hafta',\n",
       " 'aaahhh',\n",
       " 'aaahhh cryptic',\n",
       " 'aaahing',\n",
       " 'aaahing much',\n",
       " 'aaarrggghhh',\n",
       " 'aaarrggghhh plus',\n",
       " 'aaarrggghhh thanks',\n",
       " 'aaarrrggghhhhhhhhgggghhhhhh',\n",
       " 'aaarrrggghhhhhhhhgggghhhhhh dropped',\n",
       " 'aaarrrrggggghhhhh',\n",
       " 'aaarrrrggggghhhhh realized',\n",
       " 'aactually',\n",
       " 'aactually really',\n",
       " 'aahed',\n",
       " 'aahed god',\n",
       " 'aahh',\n",
       " 'aahh gw',\n",
       " 'aal',\n",
       " 'aal eliminate',\n",
       " 'aal esseneth',\n",
       " 'aal lost',\n",
       " 'aal powerful',\n",
       " 'aaldering',\n",
       " 'aaldering urllink',\n",
       " 'aamco',\n",
       " 'aamco kind',\n",
       " 'aand',\n",
       " 'aand jim',\n",
       " 'aar',\n",
       " 'aar toy',\n",
       " 'aarde',\n",
       " 'aarde maak',\n",
       " 'aargh',\n",
       " 'aargh told',\n",
       " 'aaron',\n",
       " 'aaron aaron',\n",
       " 'aaron already',\n",
       " 'aaron burr',\n",
       " 'aaron came',\n",
       " 'aaron club',\n",
       " 'aaron done',\n",
       " 'aaron friend',\n",
       " 'aaron gf',\n",
       " 'aaron heath',\n",
       " 'aaron hehe',\n",
       " 'aaron hi',\n",
       " 'aaron james',\n",
       " 'aaron lacrosse',\n",
       " 'aaron like',\n",
       " 'aaron likes',\n",
       " 'aaron love',\n",
       " 'aaron making',\n",
       " 'aaron pak',\n",
       " 'aaron parents',\n",
       " 'aaron pulled',\n",
       " 'aaron realized',\n",
       " 'aaron rowand',\n",
       " 'aaron saying',\n",
       " 'aaron seeing',\n",
       " 'aaron sent',\n",
       " 'aaron stephen',\n",
       " 'aaron talladega',\n",
       " 'aaron today',\n",
       " 'aaron turned',\n",
       " 'aarrgghh',\n",
       " 'aarrgghh missed',\n",
       " 'aaugh',\n",
       " 'aaugh sun',\n",
       " 'ab',\n",
       " 'ab aethere',\n",
       " 'ab reduction',\n",
       " 'aba',\n",
       " 'aba foundation',\n",
       " 'aba game',\n",
       " 'aba lotto',\n",
       " 'aba sessions',\n",
       " 'aba teacher',\n",
       " 'aba therapy',\n",
       " 'aba well',\n",
       " 'abab',\n",
       " 'abab cdcd',\n",
       " 'aback',\n",
       " 'aback bit',\n",
       " 'aback coz',\n",
       " 'aback see',\n",
       " 'aback sure',\n",
       " 'aback take',\n",
       " 'aballaby',\n",
       " 'aballaby nbsp',\n",
       " 'abandon',\n",
       " 'abandon every',\n",
       " 'abandon horses',\n",
       " 'abandon life',\n",
       " 'abandon little',\n",
       " 'abandon may',\n",
       " 'abandon music',\n",
       " 'abandon one',\n",
       " 'abandon program',\n",
       " 'abandon rather',\n",
       " 'abandoned',\n",
       " 'abandoned adults',\n",
       " 'abandoned although',\n",
       " 'abandoned area',\n",
       " 'abandoned attacking',\n",
       " 'abandoned catholicism',\n",
       " 'abandoned church',\n",
       " 'abandoned kitten',\n",
       " 'abandoned piers',\n",
       " 'abandoned ticket',\n",
       " 'abandoning',\n",
       " 'abandoning faith',\n",
       " 'abandoning isreal',\n",
       " 'abandoning wondering',\n",
       " 'abandonment',\n",
       " 'abandonment issues',\n",
       " 'abandons',\n",
       " 'abandons knowing',\n",
       " 'abate',\n",
       " 'abate baby',\n",
       " 'abated',\n",
       " 'abated came',\n",
       " 'abba',\n",
       " 'abba gold',\n",
       " 'abba tune',\n",
       " 'abbey',\n",
       " 'abbey eat',\n",
       " 'abbey help',\n",
       " 'abbey jay',\n",
       " 'abbey trying',\n",
       " 'abbott',\n",
       " 'abbott go',\n",
       " 'abbott makes',\n",
       " 'abbreviate',\n",
       " 'abbreviate fun',\n",
       " 'abby',\n",
       " 'abby around',\n",
       " 'abby hand',\n",
       " 'abby house',\n",
       " 'abby practically',\n",
       " 'abc',\n",
       " 'abc cbs',\n",
       " 'abc family',\n",
       " 'abc keeping',\n",
       " 'abc last',\n",
       " 'abc need',\n",
       " 'abc news',\n",
       " 'abc nightline',\n",
       " 'abcd',\n",
       " 'abcd student',\n",
       " 'abcfamily',\n",
       " 'abcfamily tapes',\n",
       " 'abcnews',\n",
       " 'abcnews com',\n",
       " 'abcnews go',\n",
       " 'abdicate',\n",
       " 'abdicate overthrown',\n",
       " 'abdomen',\n",
       " 'abdomen thighs',\n",
       " 'abducted',\n",
       " 'abducted weird',\n",
       " 'abduction',\n",
       " 'abduction tape',\n",
       " 'abductor',\n",
       " 'abductor cooperative',\n",
       " 'abdul',\n",
       " 'abdul head',\n",
       " 'abdul heard',\n",
       " 'abdul medley',\n",
       " 'abdul rahman',\n",
       " 'abe',\n",
       " 'abe called',\n",
       " 'abe fuck',\n",
       " 'abe lincoln',\n",
       " 'abegeeeeee',\n",
       " 'abegeeeeee abiis',\n",
       " 'abercrombie',\n",
       " 'abercrombie boxers',\n",
       " 'abercrombie chick',\n",
       " 'abercrombie fags',\n",
       " 'abercrombie fitch',\n",
       " 'abercrombie sells',\n",
       " 'abercrombie shit',\n",
       " 'abercrombie victoria',\n",
       " 'aberrant',\n",
       " 'aberrant really',\n",
       " 'aberration',\n",
       " 'aberration got',\n",
       " 'abfab',\n",
       " 'abfab fame',\n",
       " 'abhor',\n",
       " 'abhor middle',\n",
       " 'abhor must',\n",
       " 'abi',\n",
       " 'abi station',\n",
       " 'abide',\n",
       " 'abide add',\n",
       " 'abided',\n",
       " 'abided international',\n",
       " 'abiding',\n",
       " 'abiding christian',\n",
       " 'abiding citizens',\n",
       " 'abiding faith',\n",
       " 'abiis',\n",
       " 'abiis deh',\n",
       " 'abilities',\n",
       " 'abilities documents',\n",
       " 'abilities eminiem',\n",
       " 'abilities even',\n",
       " 'abilities first',\n",
       " 'abilities increased',\n",
       " 'abilities notary',\n",
       " 'abilities pretty',\n",
       " 'abilities rather',\n",
       " 'abilities really',\n",
       " 'abilities staff',\n",
       " 'abilities stretching',\n",
       " 'abilities trustworthy',\n",
       " 'ability',\n",
       " 'ability achieve',\n",
       " 'ability agencies',\n",
       " 'ability almost',\n",
       " 'ability analyze',\n",
       " 'ability asked',\n",
       " 'ability believe',\n",
       " 'ability cases',\n",
       " 'ability charm',\n",
       " 'ability cheer',\n",
       " 'ability collect',\n",
       " 'ability control',\n",
       " 'ability create',\n",
       " 'ability develop',\n",
       " 'ability edit',\n",
       " 'ability even',\n",
       " 'ability extract',\n",
       " 'ability fight',\n",
       " 'ability fortunate',\n",
       " 'ability function',\n",
       " 'ability gain',\n",
       " 'ability generate',\n",
       " 'ability get',\n",
       " 'ability hold',\n",
       " 'ability jump',\n",
       " 'ability keep',\n",
       " 'ability make',\n",
       " 'ability mask',\n",
       " 'ability motivation',\n",
       " 'ability nonconformist',\n",
       " 'ability outrun',\n",
       " 'ability practice',\n",
       " 'ability program',\n",
       " 'ability put',\n",
       " 'ability raise',\n",
       " 'ability really',\n",
       " 'ability repeat',\n",
       " 'ability room',\n",
       " 'ability said',\n",
       " 'ability see',\n",
       " 'ability seemingly',\n",
       " 'ability set',\n",
       " 'ability sit',\n",
       " 'ability stand',\n",
       " 'ability strive',\n",
       " 'ability take',\n",
       " 'ability talking',\n",
       " 'ability tap',\n",
       " 'ability things',\n",
       " 'ability think',\n",
       " 'ability touch',\n",
       " 'ability transform',\n",
       " 'ability use',\n",
       " 'ability walk',\n",
       " 'ability without',\n",
       " 'ability work',\n",
       " 'abismo',\n",
       " 'abismo es',\n",
       " 'abiss',\n",
       " 'abiss ituu',\n",
       " 'abit',\n",
       " 'abit nervous',\n",
       " 'abit passing',\n",
       " 'abject',\n",
       " 'abject horror',\n",
       " 'ablaze',\n",
       " 'ablaze lot',\n",
       " 'able',\n",
       " 'able access',\n",
       " 'able accommodate',\n",
       " 'able add',\n",
       " 'able afford',\n",
       " 'able answer',\n",
       " 'able anything',\n",
       " 'able anyway',\n",
       " 'able appreciate',\n",
       " 'able ascertain',\n",
       " 'able ask',\n",
       " 'able assist',\n",
       " 'able assuage',\n",
       " 'able attend',\n",
       " 'able avail',\n",
       " 'able avoid',\n",
       " 'able battle',\n",
       " 'able belt',\n",
       " 'able best',\n",
       " 'able blog',\n",
       " 'able blow',\n",
       " 'able bring',\n",
       " 'able buy',\n",
       " 'able caddy',\n",
       " 'able call',\n",
       " 'able camera',\n",
       " 'able carve',\n",
       " 'able catch',\n",
       " 'able change',\n",
       " 'able charm',\n",
       " 'able check',\n",
       " 'able click',\n",
       " 'able close',\n",
       " 'able clover',\n",
       " 'able come',\n",
       " 'able comfortably',\n",
       " 'able communicate',\n",
       " 'able complete',\n",
       " 'able conduct',\n",
       " 'able connect',\n",
       " 'able conquer',\n",
       " 'able consider',\n",
       " 'able contain',\n",
       " 'able control',\n",
       " 'able convert',\n",
       " 'able copy',\n",
       " 'able create',\n",
       " 'able deal',\n",
       " 'able decide',\n",
       " 'able define',\n",
       " 'able depend',\n",
       " 'able develop',\n",
       " 'able digest',\n",
       " 'able distinguish',\n",
       " 'able dominate',\n",
       " 'able drive',\n",
       " 'able drop',\n",
       " 'able duck',\n",
       " 'able dunk',\n",
       " 'able easily',\n",
       " 'able eat',\n",
       " 'able elf',\n",
       " 'able empty',\n",
       " 'able end',\n",
       " 'able engage',\n",
       " 'able enjoy',\n",
       " 'able entertain',\n",
       " 'able every',\n",
       " 'able expensively',\n",
       " 'able express',\n",
       " 'able face',\n",
       " 'able fall',\n",
       " 'able fast',\n",
       " 'able feel',\n",
       " 'able female',\n",
       " 'able fight',\n",
       " 'able figure',\n",
       " 'able find',\n",
       " 'able finish',\n",
       " 'able fit',\n",
       " 'able focus',\n",
       " 'able forget',\n",
       " 'able fully',\n",
       " 'able fun',\n",
       " 'able function',\n",
       " 'able gather',\n",
       " 'able get',\n",
       " 'able give',\n",
       " 'able go',\n",
       " 'able golf',\n",
       " 'able govern',\n",
       " 'able hammer',\n",
       " 'able handle',\n",
       " 'able hear',\n",
       " 'able help',\n",
       " 'able hide',\n",
       " 'able hit',\n",
       " 'able hold',\n",
       " 'able hop',\n",
       " 'able imbue',\n",
       " 'able impact',\n",
       " 'able influence',\n",
       " 'able inundate',\n",
       " 'able keep',\n",
       " 'able kick',\n",
       " 'able know',\n",
       " 'able large',\n",
       " 'able laugh',\n",
       " 'able leap',\n",
       " 'able learn',\n",
       " 'able least',\n",
       " 'able leave',\n",
       " 'able let',\n",
       " 'able liberate',\n",
       " 'able little',\n",
       " 'able live',\n",
       " 'able look',\n",
       " 'able looking',\n",
       " 'able lug',\n",
       " 'able mail',\n",
       " 'able make',\n",
       " 'able maneuver',\n",
       " 'able master',\n",
       " 'able meet',\n",
       " 'able mile',\n",
       " 'able mix',\n",
       " 'able move',\n",
       " 'able negotiate',\n",
       " 'able occasionally',\n",
       " 'able offer',\n",
       " 'able operate',\n",
       " 'able overcome',\n",
       " 'able paint',\n",
       " 'able participate',\n",
       " 'able patch',\n",
       " 'able pay',\n",
       " 'able perhaps',\n",
       " 'able pick',\n",
       " 'able play',\n",
       " 'able post',\n",
       " 'able profit',\n",
       " 'able prove',\n",
       " 'able pull',\n",
       " 'able purchase',\n",
       " 'able put',\n",
       " 'able raed',\n",
       " 'able reach',\n",
       " 'able react',\n",
       " 'able read',\n",
       " 'able recognise',\n",
       " 'able rectify',\n",
       " 'able redefine',\n",
       " 'able reduce',\n",
       " 'able relative',\n",
       " 'able relax',\n",
       " 'able release',\n",
       " 'able replace',\n",
       " 'able replaced',\n",
       " 'able report',\n",
       " 'able ride',\n",
       " 'able run',\n",
       " 'able said',\n",
       " 'able salvage',\n",
       " 'able save',\n",
       " 'able say',\n",
       " 'able see',\n",
       " 'able sell',\n",
       " 'able separate',\n",
       " 'able set',\n",
       " 'able share',\n",
       " 'able shim',\n",
       " 'able show',\n",
       " 'able shut',\n",
       " 'able sneak',\n",
       " 'able someone',\n",
       " 'able spend',\n",
       " 'able stand',\n",
       " 'able start',\n",
       " 'able stay',\n",
       " 'able stick',\n",
       " 'able stop',\n",
       " 'able stroll',\n",
       " 'able sunday',\n",
       " 'able supposed',\n",
       " 'able sure',\n",
       " 'able sustain',\n",
       " 'able take',\n",
       " 'able takes',\n",
       " 'able talk',\n",
       " 'able teach',\n",
       " 'able tell',\n",
       " 'able test',\n",
       " 'able things',\n",
       " 'able think',\n",
       " 'able travel',\n",
       " 'able turn',\n",
       " 'able type',\n",
       " 'able ugh',\n",
       " 'able urllink',\n",
       " 'able use',\n",
       " 'able utilize',\n",
       " 'able vote',\n",
       " 'able wake',\n",
       " 'able walk',\n",
       " 'able watch',\n",
       " 'able wax',\n",
       " 'able withstand',\n",
       " 'able work',\n",
       " 'able write',\n",
       " 'able yell',\n",
       " 'ableton',\n",
       " 'ableton live',\n",
       " 'ablity',\n",
       " 'ablity transportation',\n",
       " 'ablum',\n",
       " 'ablum reflection',\n",
       " 'abm',\n",
       " 'abm radars',\n",
       " 'abm treaty',\n",
       " 'abnormal',\n",
       " 'abnormal positions',\n",
       " 'abnormal screwed',\n",
       " 'aboard',\n",
       " 'aboard bb',\n",
       " 'aboard boat',\n",
       " 'aboard loved',\n",
       " 'aboard powerless',\n",
       " 'abode',\n",
       " 'abode wahoo',\n",
       " 'abodes',\n",
       " 'abodes favorite',\n",
       " 'abogados',\n",
       " 'abogados que',\n",
       " 'abomination',\n",
       " 'abomination enemies',\n",
       " 'abomination winter',\n",
       " 'aboot',\n",
       " 'aboot nbsp',\n",
       " 'aboout',\n",
       " 'aboout clarinet',\n",
       " 'abort',\n",
       " 'abort abort',\n",
       " 'abort someone',\n",
       " 'aborted',\n",
       " 'aborted highly',\n",
       " 'aborted really',\n",
       " 'aborted whatever',\n",
       " 'abortion',\n",
       " 'abortion akin',\n",
       " 'abortion edwards',\n",
       " 'abortion environment',\n",
       " 'abortion issue',\n",
       " 'abortion like',\n",
       " 'abortion matter',\n",
       " 'abortion problem',\n",
       " 'abortion procedure',\n",
       " 'abortion sex',\n",
       " 'abortion shows',\n",
       " 'abortions',\n",
       " 'abortions already',\n",
       " 'abortions void',\n",
       " 'aborts',\n",
       " 'aborts idea',\n",
       " 'abotu',\n",
       " 'abotu kids',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'abound like',\n",
       " 'abounds',\n",
       " 'abounds sunshine',\n",
       " 'abouta',\n",
       " 'abouta shop',\n",
       " 'aboutyou',\n",
       " 'aboutyou whenever',\n",
       " 'abovei',\n",
       " 'abovei close',\n",
       " 'abovementioned',\n",
       " 'abovementioned late',\n",
       " 'abovementioned nation',\n",
       " 'aboy',\n",
       " 'aboy blonde',\n",
       " 'abraham',\n",
       " 'abraham lincoln',\n",
       " 'abrams',\n",
       " 'abrams created',\n",
       " 'abrasions',\n",
       " 'abrasions road',\n",
       " 'abrasive',\n",
       " 'abrasive complicated',\n",
       " 'abreast',\n",
       " 'abreast biscomerica',\n",
       " 'abreu',\n",
       " 'abreu phi',\n",
       " 'abri',\n",
       " 'abri los',\n",
       " 'abridged',\n",
       " 'abridged history',\n",
       " 'abridged script',\n",
       " 'abridgement',\n",
       " 'abridgement actual',\n",
       " 'abridgement finished',\n",
       " 'abridgement released',\n",
       " 'abridging',\n",
       " 'abridging freedom',\n",
       " 'abroad',\n",
       " 'abroad bordeaux',\n",
       " 'abroad falls',\n",
       " 'abroad friends',\n",
       " 'abroad issue',\n",
       " 'abroad may',\n",
       " 'abroad one',\n",
       " 'abroad position',\n",
       " 'abroad sophomore',\n",
       " 'abroad yes',\n",
       " 'abrogation',\n",
       " 'abrogation principles',\n",
       " 'abruptly',\n",
       " 'abruptly asked',\n",
       " 'abruptly interrupt',\n",
       " 'abruptly poison',\n",
       " 'abs',\n",
       " 'abs bland',\n",
       " 'abs favorite',\n",
       " 'abs love',\n",
       " 'abs spy',\n",
       " 'abscess',\n",
       " 'abscess bank',\n",
       " 'abscond',\n",
       " 'abscond need',\n",
       " 'absence',\n",
       " 'absence also',\n",
       " 'absence always',\n",
       " 'absence benefit',\n",
       " 'absence cash',\n",
       " 'absence cheers',\n",
       " 'absence defintely',\n",
       " 'absence democratic',\n",
       " 'absence football',\n",
       " 'absence hillbilly',\n",
       " 'absence know',\n",
       " 'absence makes',\n",
       " 'absence matt',\n",
       " 'absence memorable',\n",
       " 'absence nbsp',\n",
       " 'absence regarding',\n",
       " 'absence reproached',\n",
       " 'absence several',\n",
       " 'absence spam',\n",
       " 'absence specific',\n",
       " 'absence yet',\n",
       " 'absent',\n",
       " 'absent bullies',\n",
       " 'absent character',\n",
       " 'absent could',\n",
       " 'absent hate',\n",
       " 'absent however',\n",
       " 'absent parent',\n",
       " 'absent show',\n",
       " 'absent two',\n",
       " 'absent vacuum',\n",
       " 'absentee',\n",
       " 'absentee ballots',\n",
       " 'absentee votes',\n",
       " 'absenteeism',\n",
       " 'absenteeism taking',\n",
       " 'absinthe',\n",
       " 'absinthe stay',\n",
       " 'abso',\n",
       " 'abso fucking',\n",
       " 'absolut',\n",
       " 'absolut ketel',\n",
       " 'absolute',\n",
       " 'absolute applies',\n",
       " 'absolute best',\n",
       " 'absolute blast',\n",
       " 'absolute bliss',\n",
       " 'absolute boredom',\n",
       " 'absolute complete',\n",
       " 'absolute declarative',\n",
       " 'absolute fabulous',\n",
       " 'absolute fairplay',\n",
       " 'absolute faith',\n",
       " 'absolute hell',\n",
       " 'absolute idiot',\n",
       " 'absolute last',\n",
       " 'absolute moxie',\n",
       " 'absolute nightmare',\n",
       " 'absolute opposition',\n",
       " 'absolute resources',\n",
       " 'absolute shite',\n",
       " 'absolute spiritual',\n",
       " 'absolute success',\n",
       " 'absolute superiority',\n",
       " 'absolute truth',\n",
       " 'absolute voice',\n",
       " 'absolute whooped',\n",
       " 'absolutely',\n",
       " 'absolutely abhor',\n",
       " 'absolutely adore',\n",
       " 'absolutely agree',\n",
       " 'absolutely amazing',\n",
       " 'absolutely attention',\n",
       " 'absolutely beautiful',\n",
       " 'absolutely blown',\n",
       " 'absolutely bubbles',\n",
       " 'absolutely called',\n",
       " 'absolutely cannot',\n",
       " 'absolutely certain',\n",
       " 'absolutely chance',\n",
       " 'absolutely change',\n",
       " 'absolutely common',\n",
       " 'absolutely condescencion',\n",
       " 'absolutely confidence',\n",
       " 'absolutely confused',\n",
       " 'absolutely convinced',\n",
       " 'absolutely could',\n",
       " 'absolutely crazy',\n",
       " 'absolutely delicious',\n",
       " 'absolutely desire',\n",
       " 'absolutely destroyed',\n",
       " 'absolutely difference',\n",
       " 'absolutely dirty',\n",
       " 'absolutely disrespectful',\n",
       " 'absolutely dogged',\n",
       " 'absolutely english',\n",
       " 'absolutely excoriated',\n",
       " 'absolutely fabulous',\n",
       " 'absolutely fantastic',\n",
       " 'absolutely feel',\n",
       " 'absolutely forbid',\n",
       " 'absolutely fucking',\n",
       " 'absolutely go',\n",
       " 'absolutely gorgeous',\n",
       " 'absolutely harmless',\n",
       " 'absolutely hate',\n",
       " 'absolutely hates',\n",
       " 'absolutely hating',\n",
       " 'absolutely hideous',\n",
       " 'absolutely highlighters',\n",
       " 'absolutely hilarious',\n",
       " 'absolutely horrible',\n",
       " 'absolutely horrifies',\n",
       " 'absolutely huge',\n",
       " 'absolutely idea',\n",
       " 'absolutely immediate',\n",
       " 'absolutely impossible',\n",
       " 'absolutely incredible',\n",
       " 'absolutely loathe',\n",
       " 'absolutely love',\n",
       " 'absolutely loved',\n",
       " 'absolutely maddening',\n",
       " 'absolutely moving',\n",
       " 'absolutely msnbc',\n",
       " 'absolutely must',\n",
       " 'absolutely necessary',\n",
       " 'absolutely nice',\n",
       " 'absolutely night',\n",
       " 'absolutely none',\n",
       " 'absolutely note',\n",
       " 'absolutely nothing',\n",
       " 'absolutely numb',\n",
       " 'absolutely nuts',\n",
       " 'absolutely obviously',\n",
       " 'absolutely offense',\n",
       " 'absolutely palast',\n",
       " 'absolutely perfectly',\n",
       " 'absolutely pissed',\n",
       " 'absolutely positively',\n",
       " 'absolutely problem',\n",
       " 'absolutely radiant',\n",
       " 'absolutely reason',\n",
       " 'absolutely refreshing',\n",
       " 'absolutely refuse',\n",
       " 'absolutely refused',\n",
       " 'absolutely ridiculous',\n",
       " 'absolutely right',\n",
       " 'absolutely rocked',\n",
       " 'absolutely salute',\n",
       " 'absolutely sense',\n",
       " 'absolutely serene',\n",
       " 'absolutely soaked',\n",
       " 'absolutely soul',\n",
       " 'absolutely spark',\n",
       " 'absolutely splash',\n",
       " 'absolutely spotless',\n",
       " 'absolutely stopped',\n",
       " 'absolutely struck',\n",
       " 'absolutely sublime',\n",
       " 'absolutely taken',\n",
       " 'absolutely talent',\n",
       " 'absolutely terrified',\n",
       " 'absolutely time',\n",
       " 'absolutely traumatized',\n",
       " 'absolutely tremendous',\n",
       " 'absolutely ucalled',\n",
       " 'absolutely use',\n",
       " 'absolutely want',\n",
       " 'absolutely women',\n",
       " 'absolutes',\n",
       " 'absolutes always',\n",
       " 'absolutes compare',\n",
       " 'absolutes else',\n",
       " 'absolutes like',\n",
       " 'absolutes none',\n",
       " 'absolutes realize',\n",
       " 'absolutes think',\n",
       " 'absolutes wary',\n",
       " 'absolutes whole',\n",
       " 'absolution',\n",
       " 'absolution couldnt',\n",
       " 'absolution many',\n",
       " 'absolution muse',\n",
       " 'absolution singing',\n",
       " 'absolutist',\n",
       " 'absolutist taste',\n",
       " 'absolutistic',\n",
       " 'absolutistic though',\n",
       " 'absolutley',\n",
       " 'absolutley amazing',\n",
       " 'absolutley random',\n",
       " 'absolutly',\n",
       " 'absolutly courage',\n",
       " 'absolutly crazy',\n",
       " 'absolutly dont',\n",
       " 'absolutly fucking',\n",
       " 'absolutly love',\n",
       " 'absolutly nothing',\n",
       " 'absolutly pointless',\n",
       " 'absolutly soaked',\n",
       " 'absolved',\n",
       " 'absolved responsibility',\n",
       " 'absolving',\n",
       " 'absolving child',\n",
       " 'absolving parents',\n",
       " 'absorb',\n",
       " 'absorb atmosphere',\n",
       " 'absorb co',\n",
       " 'absorb costs',\n",
       " 'absorb could',\n",
       " 'absorb cover',\n",
       " 'absorb loss',\n",
       " 'absorb much',\n",
       " 'absorb shots',\n",
       " 'absorbed',\n",
       " 'absorbed give',\n",
       " 'absorbed personal',\n",
       " 'absorbed problems',\n",
       " 'absorbed self',\n",
       " 'absorbed socialising',\n",
       " 'absorbed thoughts',\n",
       " 'absorbed three',\n",
       " 'absorbent',\n",
       " 'absorbent cacophony',\n",
       " 'absorbing',\n",
       " 'absorbing enchanting',\n",
       " 'absorbing fulfilling',\n",
       " 'absorbing panels',\n",
       " 'absorption',\n",
       " 'absorption problem',\n",
       " 'absoulte',\n",
       " 'absoulte favourite',\n",
       " 'absoulutely',\n",
       " 'absoulutely gorgeous',\n",
       " 'absoulutely ludicrous',\n",
       " 'abstain',\n",
       " 'abstain eating',\n",
       " 'abstain nbsp',\n",
       " 'abstained',\n",
       " 'abstained instead',\n",
       " 'abstinence',\n",
       " 'abstinence eating',\n",
       " 'abstinence hehe',\n",
       " 'abstract',\n",
       " 'abstract art',\n",
       " 'abstract proposition',\n",
       " 'abstract something',\n",
       " 'abstract thinker',\n",
       " 'abstract tonight',\n",
       " 'abstract true',\n",
       " 'abstraction',\n",
       " 'abstraction philosophical',\n",
       " 'abstraction wonderful',\n",
       " 'abstractness',\n",
       " 'abstractness introversion',\n",
       " 'absurd',\n",
       " 'absurd course',\n",
       " 'absurd crushes',\n",
       " 'absurd even',\n",
       " 'absurd explanation',\n",
       " 'absurdities',\n",
       " 'absurdities like',\n",
       " 'absurdity',\n",
       " 'absurdity hit',\n",
       " 'absurdity whole',\n",
       " 'absurdity world',\n",
       " 'absurdly',\n",
       " 'absurdly juxtaposed',\n",
       " 'abt',\n",
       " 'abt balance',\n",
       " 'abt chess',\n",
       " 'abt cleaniness',\n",
       " 'abt game',\n",
       " 'abt plus',\n",
       " 'abt since',\n",
       " 'abt somehow',\n",
       " 'abt started',\n",
       " 'abt wat',\n",
       " 'abt went',\n",
       " 'abt wrong',\n",
       " 'abt yesterday',\n",
       " 'abu',\n",
       " 'abu dhabi',\n",
       " 'abu ghraib',\n",
       " 'abu grahib',\n",
       " 'abu musab',\n",
       " 'abundance',\n",
       " 'abundance growing',\n",
       " 'abundance kinds',\n",
       " 'abundance storage',\n",
       " 'abundant',\n",
       " 'abundant free',\n",
       " 'abuse',\n",
       " 'abuse abu',\n",
       " 'abuse bad',\n",
       " 'abuse blah',\n",
       " 'abuse could',\n",
       " 'abuse deal',\n",
       " 'abuse getting',\n",
       " 'abuse health',\n",
       " 'abuse instead',\n",
       " 'abuse iraqi',\n",
       " 'abuse know',\n",
       " 'abuse matt',\n",
       " 'abuse might',\n",
       " 'abuse pandyland',\n",
       " 'abuse physical',\n",
       " 'abuse poking',\n",
       " 'abuse rights',\n",
       " 'abuse saw',\n",
       " 'abuse stomach',\n",
       " 'abuse unrealistic',\n",
       " 'abuse women',\n",
       " 'abused',\n",
       " 'abused either',\n",
       " 'abused make',\n",
       " 'abused partner',\n",
       " 'abused thinks',\n",
       " 'abused thompson',\n",
       " 'abuses',\n",
       " 'abuses outlined',\n",
       " 'abuses serious',\n",
       " 'abusing',\n",
       " 'abusing neighbor',\n",
       " 'abusing senior',\n",
       " 'abusing ways',\n",
       " 'abusive',\n",
       " 'abusive alchoholic',\n",
       " 'abusive behavior',\n",
       " 'abusive citizens',\n",
       " 'abusive environment',\n",
       " 'abusive merit',\n",
       " 'abusive others',\n",
       " 'abusive parents',\n",
       " 'abusive partner',\n",
       " 'abusive punk',\n",
       " 'abusive relationship',\n",
       " 'abusive residents',\n",
       " 'abyss',\n",
       " 'abyss chasm',\n",
       " 'abyss comapred',\n",
       " 'abyss kiss',\n",
       " 'abyss really',\n",
       " 'abyss undetermined',\n",
       " 'abyssmal',\n",
       " 'abyssmal results',\n",
       " 'ac',\n",
       " 'ac goes',\n",
       " 'ac keep',\n",
       " 'ac later',\n",
       " 'ac mug',\n",
       " 'ac office',\n",
       " 'ac weekend',\n",
       " 'acadamic',\n",
       " 'acadamic dress',\n",
       " 'academe',\n",
       " 'academe refashioned',\n",
       " 'academic',\n",
       " 'academic dress',\n",
       " 'academic education',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "vD7HJ12Pr5bq"
   },
   "outputs": [],
   "source": [
    "#This step is commented as runbook execution gets crashed for more number of input records(say >= 10000)\n",
    "doc_matrix_df = pd.DataFrame(X_train.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhyWTDQLs8Z2",
    "outputId": "27d3645a-fd4b-4f30-f4c1-57a6b628581f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Columns: 98395 entries, aa to zzzzz drop\n",
      "dtypes: int64(98395)\n",
      "memory usage: 525.5 MB\n"
     ]
    }
   ],
   "source": [
    "#This is created keeping input records as 1000 alone from the dataset for showing the output\n",
    "doc_matrix_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "517knVgvtA08",
    "outputId": "ddaf3332-11d4-4a1f-aca9-2e73bf1a7497"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa anger</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaa travel</th>\n",
       "      <th>aaarrrggghhhhhhhhgggghhhhhh</th>\n",
       "      <th>aaarrrggghhhhhhhhgggghhhhhh dropped</th>\n",
       "      <th>aaldering</th>\n",
       "      <th>aaldering urllink</th>\n",
       "      <th>aand</th>\n",
       "      <th>aand jim</th>\n",
       "      <th>aarde</th>\n",
       "      <th>aarde maak</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaron rowand</th>\n",
       "      <th>aba</th>\n",
       "      <th>aba foundation</th>\n",
       "      <th>aba sessions</th>\n",
       "      <th>aba therapy</th>\n",
       "      <th>aba well</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoned although</th>\n",
       "      <th>abandons</th>\n",
       "      <th>abandons hate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abated came</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abbreviate fun</th>\n",
       "      <th>abc</th>\n",
       "      <th>abc last</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomen thighs</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abdominal area</th>\n",
       "      <th>aberration</th>\n",
       "      <th>aberration got</th>\n",
       "      <th>abiding</th>\n",
       "      <th>abiding pedestrians</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>abidjan ivory</th>\n",
       "      <th>abilities</th>\n",
       "      <th>...</th>\n",
       "      <th>zknds smarterchild</th>\n",
       "      <th>zm</th>\n",
       "      <th>zm cos</th>\n",
       "      <th>zmattyb</th>\n",
       "      <th>zmattyb yahoo</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zodiac sign</th>\n",
       "      <th>zodiac similar</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie right</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone beyond</th>\n",
       "      <th>zone fuck</th>\n",
       "      <th>zone hope</th>\n",
       "      <th>zone large</th>\n",
       "      <th>zone one</th>\n",
       "      <th>zone somehow</th>\n",
       "      <th>zone work</th>\n",
       "      <th>zones</th>\n",
       "      <th>zones sometimes</th>\n",
       "      <th>zones today</th>\n",
       "      <th>zoniness</th>\n",
       "      <th>zoniness well</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoom first</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooms past</th>\n",
       "      <th>zovakware</th>\n",
       "      <th>zovakware lord</th>\n",
       "      <th>zua</th>\n",
       "      <th>zua watching</th>\n",
       "      <th>zun</th>\n",
       "      <th>zun charles</th>\n",
       "      <th>zun personally</th>\n",
       "      <th>zza</th>\n",
       "      <th>zza dong</th>\n",
       "      <th>zzzexy</th>\n",
       "      <th>zzzexy pathetic</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzz drop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 98395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aa anger  aaa  aaa travel  ...  zzzexy  zzzexy pathetic  zzzzz  zzzzz drop\n",
       "0    0         0    0           0  ...       0                0      0           0\n",
       "1    0         0    0           0  ...       0                0      0           0\n",
       "2    0         0    0           0  ...       0                0      0           0\n",
       "3    0         0    0           0  ...       0                0      0           0\n",
       "4    0         0    0           0  ...       0                0      0           0\n",
       "..  ..       ...  ...         ...  ...     ...              ...    ...         ...\n",
       "95   0         0    0           0  ...       0                0      0           0\n",
       "96   0         0    0           0  ...       0                0      0           0\n",
       "97   0         0    0           0  ...       0                0      0           0\n",
       "98   0         0    0           0  ...       0                0      0           0\n",
       "99   0         0    0           0  ...       0                0      0           0\n",
       "\n",
       "[100 rows x 98395 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is created keeping input records as 1000 alone from the dataset for showing the output\n",
    "doc_matrix_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFi1b66dPkLQ"
   },
   "source": [
    "6. Create a dictionary to get the count of every label i.e. the key will be label name and value will\n",
    "be the total count of the label. Check below image for reference (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "iIhQGgWetZpv"
   },
   "outputs": [],
   "source": [
    "label_counts=dict()\n",
    "\n",
    "for labels in blog_data.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label]+=1\n",
    "        else:\n",
    "            label_counts[label]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWFGOtZstdpO",
    "outputId": "2b4382e1-d69a-4192-c90b-df748788e145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'13': 42,\n",
       " '14': 212,\n",
       " '15': 602,\n",
       " '16': 440,\n",
       " '17': 1185,\n",
       " '23': 253,\n",
       " '24': 655,\n",
       " '25': 386,\n",
       " '26': 234,\n",
       " '27': 1054,\n",
       " '33': 136,\n",
       " '34': 553,\n",
       " '35': 2315,\n",
       " '36': 1708,\n",
       " '37': 33,\n",
       " '38': 46,\n",
       " '39': 79,\n",
       " '40': 1,\n",
       " '41': 20,\n",
       " '42': 14,\n",
       " '43': 6,\n",
       " '44': 3,\n",
       " '45': 16,\n",
       " '46': 7,\n",
       " 'Accounting': 4,\n",
       " 'Aquarius': 571,\n",
       " 'Aries': 4198,\n",
       " 'Arts': 45,\n",
       " 'Automotive': 14,\n",
       " 'Banking': 16,\n",
       " 'BusinessServices': 91,\n",
       " 'Cancer': 504,\n",
       " 'Capricorn': 215,\n",
       " 'Communications-Media': 99,\n",
       " 'Consulting': 21,\n",
       " 'Education': 270,\n",
       " 'Engineering': 127,\n",
       " 'Fashion': 1622,\n",
       " 'Gemini': 150,\n",
       " 'HumanResources': 2,\n",
       " 'Internet': 118,\n",
       " 'InvestmentBanking': 70,\n",
       " 'Law': 11,\n",
       " 'LawEnforcement-Security': 10,\n",
       " 'Leo': 301,\n",
       " 'Libra': 491,\n",
       " 'Marketing': 156,\n",
       " 'Museums-Libraries': 17,\n",
       " 'Non-Profit': 71,\n",
       " 'Pisces': 454,\n",
       " 'Publishing': 4,\n",
       " 'Religion': 9,\n",
       " 'Sagittarius': 1097,\n",
       " 'Science': 63,\n",
       " 'Scorpio': 971,\n",
       " 'Sports-Recreation': 80,\n",
       " 'Student': 1137,\n",
       " 'Taurus': 812,\n",
       " 'Technology': 2654,\n",
       " 'Telecommunications': 2,\n",
       " 'Virgo': 236,\n",
       " 'female': 4084,\n",
       " 'indUnk': 3287,\n",
       " 'male': 5916}"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZNUnhErPYWp"
   },
   "source": [
    "7. Transform the labels - (7.5 points)\n",
    "As we have noticed before, in this task each example can have multiple tags. To deal with\n",
    "such kind of prediction, we need to transform labels in a binary form and the prediction will be\n",
    "a mask of 0s and 1s. For this purpose, it is convenient to use MultiLabelBinarizer from sklearn\n",
    "\n",
    "a. Convert your train and test labels using MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "h1_AVP-7tr-6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ovVPyR8Uttho"
   },
   "outputs": [],
   "source": [
    "#y=binarizer.fit_transform(blog_data.labels)\n",
    "y_train=binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "flodjEI0vX0j"
   },
   "outputs": [],
   "source": [
    "y_test=binarizer.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFDqOt3F0HGF"
   },
   "source": [
    "8. Choose a classifier - (5 points)\n",
    "\n",
    "In this task, we suggest using the One-vs-Rest approach, which is implemented in\n",
    "OneVsRestClassifier class. In this approach k classifiers (= number of tags) are trained. As a basic classifier, use LogisticRegression. It is one of the simplest methods, but often it performs good enough in text classification tasks. It might take some time because the number of classifiers to train is large.\n",
    "\n",
    "a. Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label\n",
    "\n",
    "b. As One-vs-Rest approach might not have been discussed in the sessions, we are\n",
    "providing you the code for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "5L2x-EZERAev"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVJdioqhRCb9",
    "outputId": "a50cf472-2d7c-4cd5-9a12-78d108a4756c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=0.1, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=150,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver='lbfgs',C=0.1,max_iter=150)\n",
    "model=OneVsRestClassifier(model)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "Rx8bVb03wcyQ"
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DoLv_iQewge4"
   },
   "outputs": [],
   "source": [
    "y_pred_inversed = binarizer.inverse_transform(y_pred)\n",
    "y_test_inversed = binarizer.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALK6jD-v0Gye"
   },
   "source": [
    "4. Display and explain detail the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxpyOsG_2Eg5",
    "outputId": "30e4c64b-92de-4c0b-b321-332e04361ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.265\n",
      "Considering Average as Micro:\n",
      "F1 score:  0.6088956253593268\n",
      "Average precision score:  0.42856578797490535\n",
      "Average recall score:  0.48541666666666666\n",
      "\n",
      "Considering Average as Micro:\n",
      "F1 score:  0.1764978984384521\n",
      "Average precision score:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average recall score:  0.13370239643473328\n",
      "\n",
      "Considering Average as Weighted:\n",
      "F1 score:  0.5523721630405743\n",
      "Average precision score:  0.4880298778488738\n",
      "Average recall score:  0.48541666666666666\n",
      "\n",
      "Considering Average as Samples:\n",
      "F1 score:  0.5584063492063492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score:  0.5010003472222221\n",
      "Average recall score:  0.48541666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Accuracy score: ', accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Considering Average as Micro:\")\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='micro'))\n",
    "print('Average precision score: ', average_precision_score(y_test, y_pred, average='micro'))\n",
    "print('Average recall score: ', recall_score(y_test, y_pred, average='micro'))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Considering Average as Micro:\")\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('Average precision score: ', average_precision_score(y_test, y_pred, average='macro'))\n",
    "print('Average recall score: ', recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Considering Average as Weighted:\")\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('Average precision score: ', average_precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Average recall score: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Considering Average as Samples:\")\n",
    "print('F1 score: ', f1_score(y_test, y_pred, average='samples'))\n",
    "print('Average precision score: ', average_precision_score(y_test, y_pred, average='samples'))\n",
    "print('Average recall score: ', recall_score(y_test, y_pred, average='samples'))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMxDUm4Mw0gd"
   },
   "source": [
    "Lets check the average parameter for f1-score:\n",
    "\n",
    "average{‘micro’, ‘macro’, ‘samples’,’weighted’, ‘binary’} or None, default=’binary’\n",
    "This parameter is required for multiclass/multilabel targets. If None, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:\n",
    "\n",
    "'binary':\n",
    "Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n",
    "\n",
    "'micro':\n",
    "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "'macro':\n",
    "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "'weighted':\n",
    "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "'samples':\n",
    "Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZGHrA8B0GlM"
   },
   "source": [
    "5. Print the true vs predicted labels for any 5 entries from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GC170rvpV4pA",
    "outputId": "0583ff18-1ee1-4bae-c058-2a4e4e908f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label  1   at index  268   ('35', 'Aries', 'Technology', 'male')\n",
      "True Label  1   at index  268   ('35', 'Aries', 'Technology', 'male')\n",
      "Predicted Label  2   at index  200   ('Aries', 'male')\n",
      "True Label  2   at index  200   ('36', 'Aries', 'Fashion', 'male')\n",
      "Predicted Label  3   at index  867   ('Aries', 'male')\n",
      "True Label  3   at index  867   ('35', 'Aries', 'Technology', 'male')\n",
      "Predicted Label  4   at index  573   ('male',)\n",
      "True Label  4   at index  573   ('33', 'Aquarius', 'InvestmentBanking', 'male')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(1,5):\n",
    "  r = random.randint(0, 1000)\n",
    "  print(\"Predicted Label \", i, \" \", \"at index \", r, \" \", y_pred_inversed[r])\n",
    "  print(\"True Label \",i,\" \", \"at index \", r, \" \",y_test_inversed[r])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "x_Lom6cXzqn7",
    "fze-aokU0ukH"
   ],
   "name": "R8_Statistical NLP_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
